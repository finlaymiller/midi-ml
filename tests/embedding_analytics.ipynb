{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding analytics\n",
    "\n",
    "some functions to assess the usefulness of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "import torch\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTENSIONS = (\".mid\", \".midi\")\n",
    "WEIGHT_PRS = True\n",
    "# test_file = \"/media/nova/Datasets/sageev-midi/20250110/segmented/20240511-088-03/20240511-088-03_0169-0174.mid\"\n",
    "test_file = \"/media/nova/Datasets/sageev-midi/20250110/segmented/20240121-070-01/20240121-070-01_0041-0047.mid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## representation functions\n",
    "\n",
    "currently supported: pitch histogram (weighted & unweighted), spectrogram diffusion embeddings\n",
    "\n",
    "to add: clamp embeddings, blurred piano rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(midi_path: str) -> torch.tensor:\n",
    "    midi_name = os.path.splitext(os.path.basename(midi_path))[0]\n",
    "    embedding_path = os.path.join(\"..\", \"data\", \"embeddings\", midi_name + \".pt\")\n",
    "    return torch.load(embedding_path, weights_only=False).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pr(midi_path: str) -> np.ndarray:\n",
    "    return pretty_midi.PrettyMIDI(midi_path).get_pitch_class_histogram(\n",
    "        use_duration=WEIGHT_PRS, use_velocity=WEIGHT_PRS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted piano roll\n",
    "representation_function = lambda x: load_pr(x)\n",
    "\n",
    "# spectrogram diffusion embeddings\n",
    "# representation_function = lambda x: load_embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity functions\n",
    "\n",
    "currently supported: cosine similarity\n",
    "\n",
    "to add: euclidean, manhattan, ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "similarity_metric = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract representations for all segments\n",
    "p_midi = os.path.dirname(test_file)\n",
    "midi_file = os.path.basename(test_file)\n",
    "midi_segments = [\n",
    "    os.path.join(p_midi, segment)\n",
    "    for segment in os.listdir(p_midi)\n",
    "    if segment.endswith(VALID_EXTENSIONS)\n",
    "]\n",
    "print(f\"midi path is {p_midi}\")\n",
    "print(f\"midi file is {midi_file}\")\n",
    "print(f\"midi segments ({len(midi_segments)}) is {midi_segments[:3]}\")\n",
    "\n",
    "try:\n",
    "    segment_index = midi_segments.index(test_file)\n",
    "    print(f\"segment index is {segment_index}\")\n",
    "except ValueError:\n",
    "    print(f\"ERROR: couldn't find key midi file in segment list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_representations = [\n",
    "    representation_function(segment) for segment in midi_segments\n",
    "]\n",
    "\n",
    "# get the representation of the specified segment\n",
    "target_representation = representation_function(test_file)\n",
    "\n",
    "# calculate similarity for all segments\n",
    "similarities = [\n",
    "    similarity_metric(representation_function(test_file), representation)\n",
    "    for representation in segment_representations\n",
    "]\n",
    "# do a quick validity test\n",
    "key_sim = similarity_metric(\n",
    "    target_representation, segment_representations[segment_index]\n",
    ")\n",
    "print(f\"self-similarity for key midi file is {key_sim:.05f}\")\n",
    "\n",
    "# normalize similarities to [0, 1] range\n",
    "min_similarity, max_similarity = min(similarities), max(similarities)\n",
    "normalized_similarities = [\n",
    "    (sim - min_similarity) / (max_similarity - min_similarity) for sim in similarities\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity plot\n",
    "\n",
    "visualize the similarity of the chosen segment against the entire track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_path = os.path.join(\n",
    "    p_midi.replace(\"segmented\", \"unsegmented\"), p_midi.split(\"/\")[-1] + \".mid\"\n",
    ")\n",
    "\n",
    "# load file\n",
    "midi_mido = mido.MidiFile(track_path)\n",
    "midi_pm = pretty_midi.PrettyMIDI(track_path)\n",
    "\n",
    "# make piano roll\n",
    "piano_roll = midi_pm.get_piano_roll() / 128.0\n",
    "\n",
    "# trim piano roll to remove rows below lowest and above highest notes\n",
    "row_sums = piano_roll.sum(axis=1)\n",
    "non_zero_rows = np.where(row_sums > 0)[0]\n",
    "min_row, max_row = non_zero_rows[0], non_zero_rows[-1]\n",
    "trimmed_piano_roll = piano_roll[min_row : max_row + 1]\n",
    "\n",
    "# calculate dimensions for plotting\n",
    "pr_width = trimmed_piano_roll.shape[1]\n",
    "\n",
    "# calculate pixel-tick conversion ratio\n",
    "bpm = int(os.path.basename(track_path).split(\"-\")[1])\n",
    "num_ticks = mido.second2tick(\n",
    "    midi_pm.get_end_time(), midi_mido.ticks_per_beat, mido.bpm2tempo(bpm)\n",
    ")\n",
    "ticks_per_pixel = pr_width / num_ticks\n",
    "\n",
    "# extract tick positions for every 8th beat\n",
    "beat_positions = [0]\n",
    "num_beats = 0\n",
    "for track in midi_mido.tracks:\n",
    "    first_msg = track[0]\n",
    "    if first_msg.is_meta and first_msg.type == \"track_name\":\n",
    "        if first_msg.name != \"tick\":\n",
    "            continue\n",
    "\n",
    "        current_tick = 0\n",
    "        for msg in track:\n",
    "            current_tick += msg.time\n",
    "            num_beats += 1\n",
    "            if num_beats % 8 == 0:  # only include every 8th beat\n",
    "                tick_pixel = int(current_tick * ticks_per_pixel)\n",
    "                if 0 <= tick_pixel < pr_width:\n",
    "                    beat_positions.append(tick_pixel)\n",
    "\n",
    "# plot piano roll\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(f\"{test_file}\")\n",
    "plt.imshow(piano_roll, aspect=\"auto\", origin=\"lower\", cmap=\"gray\")\n",
    "\n",
    "# plot vertical lines for every 8th beat\n",
    "for beat in beat_positions:\n",
    "    plt.axvline(x=beat, color=\"red\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# similarity histogram\n",
    "plt.axhline(y=piano_roll.shape[0], xmax=0.95, color=\"white\", alpha=0.3)\n",
    "bin_edges = np.linspace(0, pr_width, num_beats // 8 + 1)\n",
    "for i, value in enumerate(similarities):\n",
    "    bin_center = (bin_edges[i] + bin_edges[i + 1]) / 2\n",
    "    color = \"blue\" if i == segment_index else \"green\"\n",
    "    plt.bar(\n",
    "        bin_center,\n",
    "        value * piano_roll.shape[0],\n",
    "        width=(bin_edges[i + 1] - bin_edges[i]),\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "        align=\"center\",\n",
    "        edgecolor=\"none\",\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file playback\n",
    "\n",
    "listen to the original file, best 3 matches, and worst match, within the same track, not within the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi_player import MIDIPlayer\n",
    "from midi_player.stylers import dark\n",
    "\n",
    "matched_sims = sorted(\n",
    "    list(zip(midi_segments, similarities)), key=lambda x: x[1], reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{os.path.basename(matched_sims[0][0])} has similarity {matched_sims[0][1]:.03f} to {midi_file}\"\n",
    ")\n",
    "MIDIPlayer(matched_sims[0][0], 300, styler=dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{os.path.basename(matched_sims[1][0])} has similarity {matched_sims[1][1]:.03f} to {midi_file}\"\n",
    ")\n",
    "MIDIPlayer(matched_sims[1][0], 300, styler=dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{os.path.basename(matched_sims[2][0])} has similarity {matched_sims[2][1]:.03f} to {midi_file}\"\n",
    ")\n",
    "MIDIPlayer(matched_sims[2][0], 300, styler=dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### third best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{os.path.basename(matched_sims[3][0])} has similarity {matched_sims[3][1]:.03f} to {midi_file}\"\n",
    ")\n",
    "MIDIPlayer(matched_sims[3][0], 300, styler=dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worst match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{os.path.basename(matched_sims[-1][0])} has similarity {matched_sims[-1][1]:.03f} to {midi_file}\"\n",
    ")\n",
    "MIDIPlayer(matched_sims[-1][0], 400, styler=dark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
